# =============================================================================
# KUBERNETES JOBS AND CRONJOBS
# =============================================================================
# This example demonstrates:
# - One-time Jobs for batch processing
# - CronJobs for scheduled tasks
# - Job parallelism and completion strategies
# - Backoff policies and retry mechanisms
# - Database backup/maintenance tasks
# =============================================================================

apiVersion: v1
kind: Namespace
metadata:
  name: batch-jobs
  labels:
    name: batch-jobs

---
# =============================================================================
# CONFIGMAP FOR JOB SCRIPTS
# =============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: job-scripts
  namespace: batch-jobs
data:
  backup.sh: |
    #!/bin/bash
    set -euo pipefail
    
    echo "Starting database backup at $(date)"
    
    # Create backup directory
    BACKUP_DIR="/backups/$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$BACKUP_DIR"
    
    # Perform MySQL dump
    mysqldump \
      --host="$MYSQL_HOST" \
      --user="$MYSQL_USER" \
      --password="$MYSQL_PASSWORD" \
      --single-transaction \
      --routines \
      --triggers \
      --all-databases \
      | gzip > "$BACKUP_DIR/full_backup.sql.gz"
    
    # Upload to S3 if configured
    if [ -n "${S3_BUCKET:-}" ]; then
      aws s3 cp "$BACKUP_DIR/full_backup.sql.gz" "s3://$S3_BUCKET/backups/$(date +%Y/%m/%d)/"
    fi
    
    echo "Backup completed successfully at $(date)"
    
  cleanup.sh: |
    #!/bin/bash
    set -euo pipefail
    
    echo "Starting cleanup job at $(date)"
    
    # Delete old sessions (older than 30 days)
    mysql -h "$MYSQL_HOST" -u "$MYSQL_USER" -p"$MYSQL_PASSWORD" -e "
      DELETE FROM sessions WHERE created_at < DATE_SUB(NOW(), INTERVAL 30 DAY);
    " "$MYSQL_DATABASE"
    
    # Delete old logs (older than 90 days)
    mysql -h "$MYSQL_HOST" -u "$MYSQL_USER" -p"$MYSQL_PASSWORD" -e "
      DELETE FROM audit_logs WHERE timestamp < DATE_SUB(NOW(), INTERVAL 90 DAY);
    " "$MYSQL_DATABASE"
    
    # Optimize tables
    mysql -h "$MYSQL_HOST" -u "$MYSQL_USER" -p"$MYSQL_PASSWORD" -e "
      OPTIMIZE TABLE sessions, audit_logs, user_activity;
    " "$MYSQL_DATABASE"
    
    echo "Cleanup completed successfully at $(date)"

  report.py: |
    #!/usr/bin/env python3
    import os
    import json
    import smtplib
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    import mysql.connector
    from datetime import datetime, timedelta
    
    def generate_report():
        conn = mysql.connector.connect(
            host=os.environ['MYSQL_HOST'],
            user=os.environ['MYSQL_USER'],
            password=os.environ['MYSQL_PASSWORD'],
            database=os.environ['MYSQL_DATABASE']
        )
        cursor = conn.cursor(dictionary=True)
        
        # Get daily statistics
        yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        
        stats = {}
        
        # User signups
        cursor.execute("""
            SELECT COUNT(*) as count FROM users 
            WHERE DATE(created_at) = %s
        """, (yesterday,))
        stats['new_users'] = cursor.fetchone()['count']
        
        # API calls
        cursor.execute("""
            SELECT COUNT(*) as count FROM api_logs 
            WHERE DATE(timestamp) = %s
        """, (yesterday,))
        stats['api_calls'] = cursor.fetchone()['count']
        
        # Error rate
        cursor.execute("""
            SELECT 
                COUNT(CASE WHEN status_code >= 500 THEN 1 END) as errors,
                COUNT(*) as total
            FROM api_logs 
            WHERE DATE(timestamp) = %s
        """, (yesterday,))
        result = cursor.fetchone()
        stats['error_rate'] = (result['errors'] / result['total'] * 100) if result['total'] > 0 else 0
        
        cursor.close()
        conn.close()
        
        return stats
    
    def send_email(stats):
        msg = MIMEMultipart()
        msg['From'] = os.environ['SMTP_FROM']
        msg['To'] = os.environ['REPORT_RECIPIENTS']
        msg['Subject'] = f"Daily Report - {datetime.now().strftime('%Y-%m-%d')}"
        
        body = f"""
        Daily Statistics Report
        =======================
        
        New Users: {stats['new_users']}
        API Calls: {stats['api_calls']}
        Error Rate: {stats['error_rate']:.2f}%
        
        Report generated at: {datetime.now().isoformat()}
        """
        
        msg.attach(MIMEText(body, 'plain'))
        
        with smtplib.SMTP(os.environ['SMTP_HOST'], int(os.environ.get('SMTP_PORT', 587))) as server:
            server.starttls()
            server.login(os.environ['SMTP_USER'], os.environ['SMTP_PASSWORD'])
            server.send_message(msg)
    
    if __name__ == '__main__':
        print(f"Generating daily report at {datetime.now()}")
        stats = generate_report()
        print(f"Stats: {json.dumps(stats, indent=2)}")
        send_email(stats)
        print("Report sent successfully")

---
# =============================================================================
# SECRET FOR JOB CREDENTIALS
# =============================================================================
apiVersion: v1
kind: Secret
metadata:
  name: job-secrets
  namespace: batch-jobs
type: Opaque
stringData:
  mysql-host: "mysql-primary.database.svc.cluster.local"
  mysql-user: "backup_user"
  mysql-password: "StrongBackupPassword123!"
  mysql-database: "main"
  s3-bucket: "company-backups"
  smtp-host: "smtp.company.com"
  smtp-user: "reports@company.com"
  smtp-password: "SmtpPassword123!"
  smtp-from: "reports@company.com"
  report-recipients: "team@company.com"

---
# =============================================================================
# ONE-TIME JOB - DATABASE MIGRATION
# =============================================================================
apiVersion: batch/v1
kind: Job
metadata:
  name: db-migration-v2
  namespace: batch-jobs
  labels:
    app: migration
    version: v2
spec:
  # Number of successful completions required
  completions: 1
  # Number of parallel pods
  parallelism: 1
  # Maximum time for the job to run
  activeDeadlineSeconds: 3600
  # Number of retries before marking as failed
  backoffLimit: 3
  # TTL for cleaning up finished jobs
  ttlSecondsAfterFinished: 86400
  
  template:
    metadata:
      labels:
        app: migration
        version: v2
    spec:
      restartPolicy: OnFailure
      
      serviceAccountName: job-runner
      
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      
      containers:
        - name: migration
          image: your-registry/migration-runner:v2
          
          command:
            - /bin/sh
            - -c
            - |
              echo "Running database migration v2..."
              alembic upgrade head
              echo "Migration completed successfully"
          
          env:
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: job-secrets
                  key: mysql-host
            - name: MYSQL_USER
              valueFrom:
                secretKeyRef:
                  name: job-secrets
                  key: mysql-user
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: job-secrets
                  key: mysql-password
          
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
          
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true

---
# =============================================================================
# CRONJOB - DATABASE BACKUP (DAILY AT 2 AM)
# =============================================================================
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup
  namespace: batch-jobs
  labels:
    app: backup
spec:
  # Run at 2:00 AM every day
  schedule: "0 2 * * *"
  # Timezone (requires Kubernetes 1.27+)
  timeZone: "America/New_York"
  # Keep last 3 successful jobs
  successfulJobsHistoryLimit: 3
  # Keep last 1 failed job
  failedJobsHistoryLimit: 1
  # Concurrency policy: Forbid, Replace, or Allow
  concurrencyPolicy: Forbid
  # Deadline for starting the job (in seconds)
  startingDeadlineSeconds: 300
  # Suspend the cron job
  suspend: false
  
  jobTemplate:
    spec:
      activeDeadlineSeconds: 7200
      backoffLimit: 2
      ttlSecondsAfterFinished: 172800
      
      template:
        metadata:
          labels:
            app: backup
            job-type: database
        spec:
          restartPolicy: OnFailure
          
          serviceAccountName: job-runner
          
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            fsGroup: 1000
          
          containers:
            - name: backup
              image: your-registry/backup-tools:latest
              
              command:
                - /bin/bash
                - /scripts/backup.sh
              
              env:
                - name: MYSQL_HOST
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-host
                - name: MYSQL_USER
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-user
                - name: MYSQL_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-password
                - name: S3_BUCKET
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: s3-bucket
              
              resources:
                requests:
                  cpu: "200m"
                  memory: "512Mi"
                limits:
                  cpu: "1000m"
                  memory: "2Gi"
              
              volumeMounts:
                - name: scripts
                  mountPath: /scripts
                - name: backup-storage
                  mountPath: /backups
              
              securityContext:
                allowPrivilegeEscalation: false
          
          volumes:
            - name: scripts
              configMap:
                name: job-scripts
                defaultMode: 0755
            - name: backup-storage
              emptyDir:
                sizeLimit: 10Gi

---
# =============================================================================
# CRONJOB - DATABASE CLEANUP (WEEKLY ON SUNDAYS AT 3 AM)
# =============================================================================
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-cleanup
  namespace: batch-jobs
  labels:
    app: cleanup
spec:
  # Run at 3:00 AM every Sunday
  schedule: "0 3 * * 0"
  timeZone: "America/New_York"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  concurrencyPolicy: Forbid
  
  jobTemplate:
    spec:
      activeDeadlineSeconds: 3600
      backoffLimit: 2
      
      template:
        metadata:
          labels:
            app: cleanup
            job-type: maintenance
        spec:
          restartPolicy: OnFailure
          serviceAccountName: job-runner
          
          containers:
            - name: cleanup
              image: mysql:8.0
              
              command:
                - /bin/bash
                - /scripts/cleanup.sh
              
              env:
                - name: MYSQL_HOST
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-host
                - name: MYSQL_USER
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-user
                - name: MYSQL_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-password
                - name: MYSQL_DATABASE
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-database
              
              resources:
                requests:
                  cpu: "100m"
                  memory: "256Mi"
                limits:
                  cpu: "500m"
                  memory: "512Mi"
              
              volumeMounts:
                - name: scripts
                  mountPath: /scripts
          
          volumes:
            - name: scripts
              configMap:
                name: job-scripts
                defaultMode: 0755

---
# =============================================================================
# CRONJOB - DAILY REPORT (EVERY DAY AT 8 AM)
# =============================================================================
apiVersion: batch/v1
kind: CronJob
metadata:
  name: daily-report
  namespace: batch-jobs
  labels:
    app: report
spec:
  # Run at 8:00 AM every day
  schedule: "0 8 * * *"
  timeZone: "America/New_York"
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  concurrencyPolicy: Forbid
  
  jobTemplate:
    spec:
      activeDeadlineSeconds: 1800
      backoffLimit: 3
      
      template:
        metadata:
          labels:
            app: report
            job-type: reporting
        spec:
          restartPolicy: OnFailure
          serviceAccountName: job-runner
          
          containers:
            - name: report
              image: python:3.11-slim
              
              command:
                - python
                - /scripts/report.py
              
              env:
                - name: MYSQL_HOST
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-host
                - name: MYSQL_USER
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-user
                - name: MYSQL_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-password
                - name: MYSQL_DATABASE
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: mysql-database
                - name: SMTP_HOST
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: smtp-host
                - name: SMTP_USER
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: smtp-user
                - name: SMTP_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: smtp-password
                - name: SMTP_FROM
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: smtp-from
                - name: REPORT_RECIPIENTS
                  valueFrom:
                    secretKeyRef:
                      name: job-secrets
                      key: report-recipients
              
              resources:
                requests:
                  cpu: "100m"
                  memory: "256Mi"
                limits:
                  cpu: "500m"
                  memory: "512Mi"
              
              volumeMounts:
                - name: scripts
                  mountPath: /scripts
          
          volumes:
            - name: scripts
              configMap:
                name: job-scripts
                defaultMode: 0755

---
# =============================================================================
# PARALLEL JOB - DATA PROCESSING
# =============================================================================
apiVersion: batch/v1
kind: Job
metadata:
  name: data-processor
  namespace: batch-jobs
  labels:
    app: processor
spec:
  # Process 10 items total
  completions: 10
  # Run 3 pods in parallel
  parallelism: 3
  # Indexed completion mode for work queue pattern
  completionMode: Indexed
  activeDeadlineSeconds: 7200
  backoffLimit: 5
  
  template:
    metadata:
      labels:
        app: processor
    spec:
      restartPolicy: OnFailure
      
      containers:
        - name: processor
          image: your-registry/data-processor:latest
          
          command:
            - /bin/sh
            - -c
            - |
              echo "Processing batch $JOB_COMPLETION_INDEX"
              python process_batch.py --batch-id=$JOB_COMPLETION_INDEX --total-batches=10
              echo "Batch $JOB_COMPLETION_INDEX completed"
          
          env:
            - name: JOB_COMPLETION_INDEX
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['batch.kubernetes.io/job-completion-index']
          
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "2000m"
              memory: "4Gi"

---
# =============================================================================
# SERVICE ACCOUNT FOR JOBS
# =============================================================================
apiVersion: v1
kind: ServiceAccount
metadata:
  name: job-runner
  namespace: batch-jobs
automountServiceAccountToken: false

---
# =============================================================================
# ROLE FOR JOB RUNNER
# =============================================================================
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: job-runner-role
  namespace: batch-jobs
rules:
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get", "list"]
  - apiGroups: [""]
    resources: ["secrets"]
    resourceNames: ["job-secrets"]
    verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: job-runner-binding
  namespace: batch-jobs
subjects:
  - kind: ServiceAccount
    name: job-runner
    namespace: batch-jobs
roleRef:
  kind: Role
  name: job-runner-role
  apiGroup: rbac.authorization.k8s.io
